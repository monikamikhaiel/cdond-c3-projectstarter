version: 2.1

commands:
   install-dependencies:
     description: Install aws cli and ansible 
     steps:
      - run:
          name: aws
          command: |
                    curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
                    unzip awscliv2.zip
                    sudo ./aws/install
      - run:
          name: ansible
          command: |
                   sudo apt update
                   sudo apt install software-properties-common
                   sudo add-apt-repository --yes --update ppa:ansible/ansible
                   sudo apt install ansible --yes
   install-nodejs-npm:
        description: Install nodejs and npm from nodesource 
        steps:
          - run:
              name: node
              command: |
                    curl -fsSL https://deb.nodesource.com/setup_13.x | sudo -E bash -
                    sudo apt-get install -y nodejs
   destroy-environment:
    description: Destroy back-end and front-end cloudformation stacks given a workflow ID.
    parameters:
      workflow_ID:
        type: string 
        default: ${CIRCLE_WORKFLOW_ID:0:5}
    steps:
      - run:
          name: Destroy environments
          when: on_fail
          command: |
             aws cloudformation delete-stack --stack-name "ApplicationInfrastructureBACK${CIRCLE_WORKFLOW_ID:0:5}"
             aws s3 rm s3://udapeople-${CIRCLE_WORKFLOW_ID:0:5} --recursive
             aws cloudformation delete-stack --stack-name "ApplicationInfrastructureFRONT${CIRCLE_WORKFLOW_ID:0:5}"  
      #        echo "[web]" > .circleci/ansible/inventory.txt
      #        cat .circleci/ansible/inventory.txt
      # - persist_to_workspace:
      #     root: ~/
      #     paths:
      #       - project/.circleci/ansible/inventory.txt

   revert-migrations:
      description: Revert the last migration if successfully run in the current workflow.
      parameters:
        workflow_ID:
          type: string 
          default: ${CIRCLE_WORKFLOW_ID:0:5} 
      steps:
      - run:
          name: Revert migrations
          # Add when this will run
          when: on_fail
          command: |
            # Curl command here to see if there was a successful migration associated with the workflow id, store result in SUCCESS variable
            result=$(curl -k  https://kvdb.io/K33QBbPMsWuLqHyKSuNPRx/migration_result_${CIRCLE_WORKFLOW_ID:0:5})

            SUCCESS="sucess"
            if(( $SUCCESS!=$result )); 
            then
             cd ~/project/backend
             npm install
             npm install migration:revert
            #  Add revert code here. You can find this in the Getting Started section.
              # exit 1
            fi
            
jobs:
  build-frontend:
    docker:
      - image: cimg/node:13.8.0
    steps:
      - checkout
      - restore_cache: # cache --> hierarchy of files under a key. 
          keys: [frontend-dependencies]
      - run:
          name: Build front-end
          command: |
            cd frontend
            npm install
            npm run build
      - save_cache:
          paths: [frontend/node_modules]
          key: frontend-dependencies # ta2riban dah zay elcookie name 

  build-backend:
    docker:
      - image: cimg/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [backend-dependencies]
      - run:
          name: Back-end build
          command: |
            cd backend          
            npm install
            npm run build
      - save_cache:
          paths: [backend/node_modules]
          key: backend-dependencies

  test-frontend:
    docker:
      - image: cimg/node:13.8.0
    steps:
      - checkout
      - restore_cache: # cache --> hierarchy of files under a key. 
          keys: [frontend-dependencies] # from the previous job
      - run:
          name: front-end test
          command: |
            cd frontend
            npm run test # same as npm test in order to run the scriptin package.json scripts 
      - save_cache:
          paths: [frontend/node_modules]
          key: frontend-dependencies # ta2riban dah zay elcookie name 
                
  test-backend:
    docker:
      - image: cimg/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [backend-dependencies]
      - run:
          name: Back-end test
          command: |
            cd backend
            npm run test
      - save_cache:
          paths: [backend/node_modules]
          key: backend-dependencies
 # scan vulnerability
            
  scan-frontend:
    docker:
      - image: cimg/node:13.8.0
    steps:
      - checkout
      - restore_cache: # cache --> hierarchy of files under a key. 
          keys: [frontend-dependencies] # from the previous job
      - run:
          name: front-end scan
          command: |
            cd frontend
            npm install
            npm audit fix --force
      - save_cache:
          paths: [frontend/node_modules]
          key: frontend-dependencies # ta2riban dah zay elcookie name 
                
  scan-backend:
    docker:
      - image: cimg/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [backend-dependencies]
      - run:
          name: Back-end scan
          command: |
            cd backend
            npm install # check for unsecure packages 
            npm audit fix --force
      - save_cache:
          paths: [backend/node_modules]
          key: backend-dependencies
  # run-migration:        
  #   docker:
  #     - image: cimg/node:13.8.0
  #   steps:
  #     - checkout
  #     - restore_cache:
  #         keys: [backend-dependencies]
  #     - run:
  #         name:  run-migration
  #         command: |
  #           cd backend
  #           npm install 
  #           npm run migrations
  #     - save_cache:
  #         paths: [backend/node_modules]
  #         key: backend-dependencies
  deploy-infrastructure:
    docker:
      - image: cimg/base:stable
    steps:
      - checkout
      - install-dependencies
      - run:
          name: Ensure back-end infrastructure exists
          command: |
            aws cloudformation deploy \
              --template-file .circleci/files/backend.yml \
              --tags project=monika-infrastructure-deployment\
               --stack-name "ApplicationInfrastructureBACK${CIRCLE_WORKFLOW_ID:0:5}" \
               --parameter-overrides ID="${CIRCLE_WORKFLOW_ID:0:5}"
              # exit 1
      - run:
          name: Ensure front-end infrastructure exist
          command: |
            aws cloudformation deploy \
              --template-file .circleci/files/frontend.yml \
              --tags project=monika-infrastructure-deployment \
              --stack-name "ApplicationInfrastructureFRONT${CIRCLE_WORKFLOW_ID:0:5}" \
              --parameter-overrides ID="${CIRCLE_WORKFLOW_ID:0:5}"  
              # exit 1
      - run:
          name: Add back-end ip to ansible inventory
          command: |
                    echo "[web]" > .circleci/ansible/inventory.txt
                    # echo "\n" > .circleci/ansible/inventory.txt
                    BACKEND_PUBLIC_IP=$(aws ec2 describe-instances \
                                   //--filters "Name=tag:Name,Values=backend-${CIRCLE_WORKFLOW_ID:0:5}"  \ 
                                   --query 'Reservations[*].Instances[*].PublicIpAddress' --output text)
                    echo $BACKEND_PUBLIC_IP >> .circleci/ansible/inventory.txt
                    cat .circleci/ansible/inventory.txt

      - persist_to_workspace:
      #     root: ~/
      #     paths:
      #       - project/.circleci/ansible/inventory.txt
          root: ~/
          paths:
            - project/.circleci/ansible/inventory.txt
      - destroy-environment      
      # Here's where you will add some code to rollback on failure      

  configure-infrastructure:
    docker:
      # Docker image here that supports Ansible
      - image: cimg/base:stable
    steps:
      # Checkout code from git
      - checkout
      - install-dependencies
      # Add ssh keys with fingerprint
      - add_ssh_keys:
          fingerprints: ["10:14:bb:e2:f4:0c:ec:a1:0c:e3:f3:f8:5b:e2:69:01"]
      # attach workspace
      - attach_workspace:
          # Must be absolute path or relative path from working_directory
          at: ~/
      - run:
          name: Configure server
          command: |
               cat .circleci/ansible/inventory.txt
               ansible-playbook -i .circleci/ansible/inventory.txt  .circleci/ansible/configure-server.yml 
           
      # - run:
      #     name: Install dependencies
      #     command: |
      #       cat .circleci/ansible/inventory.txt
      #       ansible-playbook -i .circleci/ansible/inventory.txt .circleci/ansible/deploy-backend.yml 
#             exit 1
      - destroy-environment      

#             exit 1
#       # Here's where you will add some code to rollback on failure      
  run-migrations:
    docker:
      - image: cimg/node:13.8.0
    steps:
      - checkout
      - restore_cache:
          keys: [backend-dependencies]
      - run:
          name:  run-migration
          command: |
            curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
            unzip awscliv2.zip
            sudo ./aws/install  
            cd backend
            # npm cache clean --force
            # npm cache verify
            npm install 
            # npm audit fix --force
            npm run migrations > migrations.log
            cat migrations.log
      - save_cache:
          paths: [backend/node_modules]
          key: backend-dependencies
      - run:
          name: Send migration results to KVDB
          command: |
                    if grep -q "has been executed successfully" ~/project/backend/migrations.log 
                    then 
                        curl https://kvdb.io/K33QBbPMsWuLqHyKSuNPRx/migration_result_${CIRCLE_WORKFLOW_ID:0:5} -d 'success'
                    fi 
  
#             exit 1
#      # Here's where you will add some code to rollback on failure 
 
      - destroy-environment   
      - revert-migrations

  deploy-frontend:
    docker:
      # Docker image here that supports AWS CLI
     - image: cimg/base:stable
    steps:
      # Checkout code from git
      - checkout
      - install-nodejs-npm
      - restore_cache: # cache --> hierarchy of files under a key. 
          keys: [frontend-dependencies]
      - run:
          name: Install dependencies
          command: |
           cd frontend
           npm i       
      - run:
          name: Get backend url
          command: |
            curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
            unzip awscliv2.zip
            sudo ./aws/install
            # your code here
            BACKEND_IP=$(aws ec2 describe-instances --query 'Reservations[*].Instances[*].PublicIpAddress' --output text)
            # echo "Backend EC2 IP is ${BACKEND_IP}"
            export API_URL="http://${BACKEND_IP}:3030"
            echo "${API_URL}"
      - run:
          name: Deploy frontend objects
          command: |
            # your code here
             cd frontend
             npm run build 
            #   need to copy the files in dist to the s3 bucket
            aws s3 cp dist  s3://udapeople-${CIRCLE_WORKFLOW_ID:0:5} --recursive
      # Here's where you will add some code to rollback on failure 
      - destroy-environment   
      - revert-migrations     
                    
  deploy-backend:
    docker:
      # Docker image here that supports AWS CLI
      - image: cimg/base:stable
    steps:
      # Checkout code from git
      - checkout
      - install-dependencies
      - install-nodejs-npm
      - add_ssh_keys:
          fingerprints: ["10:14:bb:e2:f4:0c:ec:a1:0c:e3:f3:f8:5b:e2:69:01"]
      - restore_cache:
          keys: [backend-dependencies]          
      - run:
          name: Install dependencies
          command: |
                    cd backend
                    npm run build # dal eli beyproduce el dist folder
                    #  adding env variable  
                    echo NODE_ENV=production > .env
                    echo VERSION=1 >> .env
                    echo TYPEORM_CONNECTION=postgres >> .env
                    echo TYPEORM_MIGRATIONS_DIR=./src/migrations >> .env
                    echo TYPEORM_ENTITIES=./src/modules/domain/**/*.entity.ts >> .env
                    echo TYPEORM_MIGRATIONS=./src/migrations/*.ts >> .env
                    echo TYPEORM_HOST=${TYPEORM_HOST} >> .env
                    echo TYPEORM_PORT=${TYPEORM_PORT} >> .env
                    echo TYPEORM_USERNAME=${TYPEORM_USERNAME} >> .env
                    echo TYPEORM_PASSWORD=${TYPEORM_PASSWORD} >> .env
                    echo TYPEORM_DATABASE=${TYPEORM_DATABASE} >> .env
                    # ls dist/*
                    # ls package*
                    # tar cf dependencies.tar backend 
                    pwd
                    cd ..
                    tar cf dependencies.tar backend 
                    cp dependencies.tar .circleci/ansible/roles/deploy/files/dependencies.tar  # add the packages to files ansible 
      # attach workspace
      - attach_workspace:
          # Must be absolute path or relative path from working_directory
          at: ~/                    
      - run:
          name: Deploy backend
          command: |
                    cat .circleci/ansible/inventory.txt
                    ansible-playbook -i .circleci/ansible/inventory.txt .circleci/ansible/deploy-backend.yml 

      # Here's where you will add some code to rollback on failure 
      - destroy-environment   
      - revert-migrations 

  smoke-test:
    docker:
      # Lightweight Docker image 
    - image: cimg/base:stable
    steps:
      # Checkout code from git
      - checkout
      - install-dependencies
      # - install-nodejs-npm
      - run:
          name: Install dependencies
          command: |
            # your code here
      - run:
          name: Frontend smoke test.
          command: |
            # your code here
            Frontend_url=http://udapeople-${CIRCLE_WORKFLOW_ID:0:5}.s3-website.us-east-1.amazonaws.com
            curl -s $Frontend_url
            if curl -s $Frontend_url | grep "Welcome"
            then 
               exit 0
            else 
               exit 1 
            fi             
      - run:
          name: Get backend url
          command: |
            # your code here
            BACKEND_IP=$(aws ec2 describe-instances --query 'Reservations[*].Instances[*].PublicIpAddress' --output text)
            # echo "Backend EC2 IP is ${BACKEND_IP}"
            export API_URL="http://${BACKEND_IP}:3030"
            # cat /tmp/hello.txt
      - run:
          name: Backend smoke test.
          command: |
            # your code here 
            BACKEND_IP=$(aws ec2 describe-instances --query 'Reservations[*].Instances[*].PublicIpAddress' --output text)
            # echo "Backend EC2 IP is ${BACKEND_IP}"
            export API_URL="http://${BACKEND_IP}:3030"
            # Check the status of the bckend url
            echo " $API_URL/api/status" 
            echo ` curl -s $API_URL/api/status`
            if curl -s $API_URL/api/status | grep "ok"
            then 
               exit 0
            else 
               exit 1 
            fi 
      # - run:
      #     name: deploy cloudfront 
      #     command: |
      #       # your code here    
      #       aws cloudformation deploy \
      #         --template-file .circleci/files/cloudfront.yml \
      #         --tags project=monika-infrastructure-deployment \
      #         --stack-name "ApplicationInfrastructuredistrib${CIRCLE_WORKFLOW_ID:0:5}" \
      #         --parameter-overrides ID="${CIRCLE_WORKFLOW_ID:0:5}"  



      # Here's where you will add some code to rollback on failure 
      - destroy-environment   
      - revert-migrations 

  cloudfront-update:
    docker:
      # Docker image here that supports AWS CLI
    - image: cimg/base:stable
    steps:
      # Checkout code from git
      - checkout
      - install-dependencies
      - install-nodejs-npm
      - run:
          name: Install dependencies
          command: |
            # your code here
             export OldWorkflowID=$(aws cloudformation list-exports \
             --query "Exports[?Name==\`WorkflowID\`].Value" --no-paginate --output text)
             echo $OldWorkflowID
             curl -k  https://kvdb.io/K33QBbPMsWuLqHyKSuNPRx/old_workflow_id -d "${OldWorkflowID}"
      - run:
          name: Update cloudfront distribution
          command: |
            # your code here
            aws cloudformation deploy \
              --template-file .circleci/files/cloudfront.yml \
              --tags project=monika-infrastructure-deployment \
              --stack-name "ApplicationInfrastructuredistrib${CIRCLE_WORKFLOW_ID:0:5}" \
              --parameter-overrides WorkflowID="${CIRCLE_WORKFLOW_ID:0:5}"  
              
      - destroy-environment   
      - revert-migrations                           
      # Here's where you will add some code to rollback on failure  

  cleanup:
    docker:
    - image: cimg/base:stable
    steps:
      # Checkout code from git
      - checkout
      - install-dependencies      
      - run:
          name: Get old stack workflow id
          command: |
            # your code here
            #  from kvdb not from query 
            export OldWorkflowID=$(curl -k  https://kvdb.io/K33QBbPMsWuLqHyKSuNPRx/old_workflow_id)
            echo "Value of old workflowID $OldWorkflowID" 
            # export STACKS=[] #put the list of stacks here
            export STACKS=($(aws cloudformation list-stacks \
             --query "StackSummaries[*].StackName" \
             --stack-status-filter CREATE_COMPLETE  --no-paginate --output text))
             echo $STACKS

      - run:
          name: Remove old stacks and files
          command: |
            if [[ "${STACKS[@]}" =~ "${OldWorkflowID}" && ${OldWorkflowID} !="" ]]
            then
            # same commands as the cmd -->    destroy-environment:
             aws cloudformation delete-stack --stack-name "ApplicationInfrastructureBACK${OldWorkflowID}"
             aws s3 rm s3://udapeople-${OldWorkflowID} --recursive
             aws cloudformation delete-stack --stack-name "ApplicationInfrastructureFRONT${OldWorkflowID}"  
            fi
            

workflows:
  default:
    jobs:
      - build-frontend
      - build-backend
      - test-frontend:
          requires: [build-frontend]
      - test-backend:
          requires: [build-backend]
      - scan-backend:
          requires: [build-backend]
      - scan-frontend:
          requires: [build-frontend]
      # - run-migration:
      #     requires: [scan-backend]          
      - deploy-infrastructure:
          requires: [test-frontend, test-backend, scan-frontend, scan-backend]
          # filters:
          #   branches:
          #     only: [test-feature-branch]
      - configure-infrastructure:
          requires: [deploy-infrastructure]
      - run-migrations:
          requires: [test-frontend, test-backend, scan-frontend, scan-backend]
      - deploy-frontend:
          requires: [run-migrations,configure-infrastructure]
      - deploy-backend:
          requires: [run-migrations,configure-infrastructure]
      - smoke-test:
          requires: [deploy-backend, deploy-frontend]
      - cloudfront-update:
          requires: [smoke-test]
      - cleanup:
          requires: [cloudfront-update]